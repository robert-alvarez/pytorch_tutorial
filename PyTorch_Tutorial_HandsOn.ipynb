{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch\n",
    "\n",
    "## Robert Alvarez - Head of Data Science at Podium Education\n",
    "\n",
    "\n",
    "![](data/img/odsc.png)\n",
    "\n",
    "<!---![](data/img/pydata-miami-logo.png)--->\n",
    "\n",
    "<!---![](data/img/GAIC.jpg)--->\n",
    "\n",
    "![](data/img/Robert_Alvarez.jpg)\n",
    "\n",
    "![](data/img/pytorch_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing PyTorch (on Google Server)\n",
    "\n",
    "Go to https://colab.research.google.com and sign in with your Google account. If you do not have a Google account you can create one. From there you can create a new notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install using Conda (for local installation)\n",
    "\n",
    "`conda install pytorch torchvision -c pytorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T13:46:07.001094Z",
     "start_time": "2019-04-29T13:46:03.395124Z"
    }
   },
   "outputs": [],
   "source": [
    "# usual suspects\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import requests\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cycler import cycler\n",
    "\n",
    "# the good stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# standard sklearn import\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# minor changes to plotting functions\n",
    "import matplotlib.pyplot as plt\n",
    "cmap=plt.cm.tab10\n",
    "c = cycler('color', cmap(np.linspace(0,1,10)))\n",
    "plt.rcParams[\"axes.prop_cycle\"] = c\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# change margin size of jupyter notebook\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all necessary files for the live tutorial\n",
    "# Post ODSC pull from GitHub Repo github.com/robert-alvarez\n",
    "\n",
    "data_url = 'https://www.dropbox.com/s/z0ilg0u8rsl2udz/pytorch_data.zip?dl=1'\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    # Download the data zip file.\n",
    "    response = requests.get(data_url, stream=True)\n",
    "    zip_path = 'pytorch_data.zip'\n",
    "    with open(zip_path, 'wb') as f:\n",
    "        shutil.copyfileobj(response.raw, f)\n",
    "    # Unzip the file.\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall()\n",
    "    # Clean up.\n",
    "    os.remove(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "What is PyTorch?\n",
    "\n",
    "* It is a replacement for NumPy to use GPUs\n",
    "* A deep learning platform built for flexibility and speed\n",
    "\n",
    "\n",
    "## Tensor Overview\n",
    "What are tensors?\n",
    "\n",
    "Tensors are similar to NumPy's `ndarrays`\n",
    "\n",
    "We normally think of tensors as a generalization of matrices. In fact, matrices are 2-D tensors!\n",
    "\n",
    "![](https://image.slidesharecdn.com/tensordecomposition-170301235239/95/a-brief-survey-of-tensors-5-638.jpg?cb=1488412458)\n",
    "\n",
    "Here is a great visualization of tensors from 1-D to 5-D\n",
    "\n",
    "![](img/tensor_viz.jpeg)\n",
    "\n",
    "As mentioned before, since tensors are generalizations of matrices, we should be able to create them in similar ways. We can also expect *most* operations to stay the same. In particular, addition of tensors is the same as for matrices. Multiplication is a bit different, but we won't have to concern ourselves with that in this lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Types\n",
    "\n",
    "Torch defines eight CPU tensor types and eight GPU tensor types:\n",
    "\n",
    "| Data type                | dtype                             | CPU Tensor           | GPU Tensor                |\n",
    "|--------------------------|-----------------------------------|----------------------|---------------------------|\n",
    "| 32-bit floating point    | `torch.float32` or `torch.float`  | `torch.FloatTensor`  | `torch.cuda.FloatTensor`  |\n",
    "| 64-bit floating point    | `torch.float64` or `torch.double` | `torch.DoubleTensor` | `torch.cuda.DoubleTensor` |\n",
    "| 16-bit floating point    | `torch.float16` or `torch.half`   | `torch.HalfTensor`   | `torch.cuda.HalfTensor`   |\n",
    "| 8-bit integer (unsigned) | `torch.uint8`                     | `torch.ByteTensor`   | `torch.cuda.ByteTensor`   |\n",
    "| 8-bit integer (signed)   | `torch.int8`                      | `torch.CharTensor`   | `torch.cuda.CharTensor`   |\n",
    "| 16-bit integer (signed)  | `torch.int16` or `torch.short`    | `torch.ShortTensor`  | `torch.cuda.ShortTensor`  |\n",
    "| 32-bit integer (signed)  | `torch.int32` or `torch.int`      | `torch.IntTensor`    | `torch.cuda.IntTensor`    |\n",
    "| 64-bit integer (signed)  | `torch.int64` or `torch.long`     | `torch.LongTensor`   | `torch.cuda.LongTensor`   |\n",
    "\n",
    "**Note**: Tensor types need to match when doing calculations with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy ndarrays vs PyTorch Tensors\n",
    "\n",
    "Let's look at the differences between these two common methods of handling arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In numpy, we create tensors (arrays) in the following way\n",
    "x1 = np.random.rand(5,3)\n",
    "print(f\"x1 =\\n {x1}\\n\")\n",
    "\n",
    "# Similar to numpy we can create random tensors\n",
    "t1 = torch.rand(5,3, dtype=torch.float64)\n",
    "print(f\"t1 =\\n {t1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the type\n",
    "print(f\"t1 is a {type(t1)}\")\n",
    "print(f\"x1 is a {type(x1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"t1 is dtype {t1.dtype}\")\n",
    "print(f\"x1 is dtype {x1.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 3-D tensor in torch and numpy\n",
    "t2 = torch.rand(2, 3, 5)\n",
    "print(f\"t2 =\\n {t2}\\n\")\n",
    "\n",
    "x2 = np.random.rand(2, 3, 5)\n",
    "print(f\"x2 =\\n {x2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_tensor = torch.zeros(5,3, dtype=torch.long)\n",
    "long_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_tensor = torch.zeros(5,3, dtype=torch.float64)\n",
    "float_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_tensor + float_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_tensor + long_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also create explicit tensors\n",
    "x = torch.tensor([2., 3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method creates a new tensor \"y\" that has the same properties (e.g. dtype) as the original tensor \"x\"\n",
    "y = x.new_ones(5,3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's a size method as well\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can add tensors as well in the usual way you expect\n",
    "x = torch.rand(5,3)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also add like this\n",
    "torch.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR like this!\n",
    "# The `*_` method works just like `inplace=True` in pandas\n",
    "y.add_(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see!\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing works just like in numpy\n",
    "y[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can reshape tensors as well though it's called \"view\" in pytorch\n",
    "# support for 'reshape' has been added\n",
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "w = x.reshape(2, -1)\n",
    "print(x.size(), y.size(), z.size(), w.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on torch operations can be found here: https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to/from PyTorch & NumPy is easy\n",
    "a = torch.ones(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy\n",
    "b = a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do we expect this result to be?\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from numpy to torch\n",
    "c = np.random.randn(4,5)\n",
    "print(c)\n",
    "d = torch.from_numpy(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd - AKA why PyTorch is awesome\n",
    "\n",
    "Central to all Neural Networks in PyTorch is the `autograd` package. \n",
    "\n",
    "The `autograd` package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, \n",
    "which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n",
    "\n",
    "Let's look at a basic example of this before returning to our Neural Networks again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor and set requires_grade=True to track computation with it\n",
    "x = torch.ones(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some operation on said tensor\n",
    "y = 3*x + 7\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because y was created as a result of an operation, it now has a grad_fn method\n",
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do more stuff to y (and thus x) and calculate its derivatives\n",
    "z = 2*y**2\n",
    "w = z.mean()\n",
    "\n",
    "print(z, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation in one line!\n",
    "w.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# et voila!\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(n,2) \n",
    "x[:,0].uniform_(-1.,1)\n",
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([3.,2]); a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x@a + torch.randn(n)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0], y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, y_pred): \n",
    "    return ((y - y_pred)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([-1.,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = x@a\n",
    "mse(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0],y)\n",
    "plt.scatter(x[:,0],y_hat);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Parameter(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update():\n",
    "    '''\n",
    "    function to update tensor using SGD\n",
    "    '''\n",
    "    y_hat = x@a\n",
    "    loss = mse(y, y_hat)\n",
    "    if t % 10 == 0: print(loss)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        a.sub_(lr * a.grad)\n",
    "        a.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "for t in range(100): \n",
    "    update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0], y)\n",
    "plt.scatter(x[:,0], x@a.detach());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Equations\n",
    "Although we solved for the line of best fit using stochastic gradient descent,\n",
    "we could have also used the [Normal Equations](https://en.wikipedia.org/wiki/Linear_least_squares#Derivation_of_the_normal_equations) given by\n",
    "\n",
    "$$ \\theta = (X^T X)^{-1} X^T \\vec y$$\n",
    "\n",
    "where $\\theta$ is the vector we called `a_guess`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise:\n",
    "# Use pytorch to solve for theta using the normal equations\n",
    "# plot your result when you are finished\n",
    "\n",
    "# Code goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks (NNs) are special forms of nonlinear regressions where the decision system for which the NN is built mimics the way \n",
    "the brain is supposed to work (whether it works like a NN is up for grabs of course).\n",
    "\n",
    "Like many of the algorithms we have seen before, it is a supervised learning technique that can perform complex tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic building block of a neural network is a perceptron. A perceptron is like a neuron in a human brain. It takes inputs \n",
    "(e.g. sensory in a real brain) and then produces an output signal. An entire network of perceptrons is called a neural net.\n",
    "\n",
    "![linear regression](data/img/NN_perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, a perceptron could have more or fewer inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of assigning equal weight to each of the inputs, we can assign real numbers $w_1, w_2, \\ldots$ expressing the importance of the respective inputs to the output. The nueron's output, 0 or 1, is determined whether the weighted sum $\\sum_j w_j x_j$ is less than or greater than some *threshold value*.\n",
    "\n",
    "Perceptrons may emit continuous signals or binary $(0,1)$ signals. In the case of a credit card application, the final perceptron is a binary one (approved or denied). Such perceptrons are implemented by means of squashing functions. For example, a really simple squashing function is one that issues a 1 if the function value is positive and a $-1$ if it is negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put this in more mathematical terms, let $z = \\sum_{j=0}^n w_j x_j$ . \n",
    "Then the *activation function* $\\phi(z)$ is defined as \n",
    "\n",
    "$$\n",
    "\\phi(z) =\n",
    "\\begin{cases}\n",
    "-1 & \\text{if } z < \\theta\\\\\n",
    " 1 & \\text{if } z \\geq \\theta\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/img/activation-function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole point of the perceptron is to mimic how a single nueron in the brain works: it either *fires* or it doesn't. Thus, the \n",
    "perceptron rule is fairly simple and can be summarized by the following steps.\n",
    "​\n",
    "* Initialize the weights to zero or small random numbers\n",
    "* For each training sample $\\textbf{x}_n$ perform the following steps:\n",
    "    * Compute the output value $y$\n",
    "    * Calculate error in $y$ vs $\\hat y$\n",
    "    * Update the weights\n",
    "  \n",
    "Here, the output value is the class label predicted by the activation function that we defined earlier, and the\n",
    "simultaneous update of weight $w_j$ in the weight vector $\\textbf{w}$ can be more formally written as\n",
    "​\n",
    "$$\\bar w_j = w_j + \\Delta w_j$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a model\n",
    "\n",
    "Let's go back to our linear perceptron. It has the following parameters:\n",
    "\n",
    "* $x_i$: inputs\n",
    "* $y$ : output\n",
    "* $w_i$: learned weights\n",
    "\n",
    "What we would like to do is adjust the $w_i$'s until our model has the best fit.\n",
    "\n",
    "First, initialize the $w_i$'s in some meaningful way (usually they're drawn from a randon uniform distribution).\n",
    "\n",
    "Then, we put it into our usual **algorithm workflow:**\n",
    "\n",
    "* calculate prediction $\\hat y$\n",
    "* calculate Loss function $L(y, \\hat y)$\n",
    "* update weights using backpropagation\n",
    "\n",
    "### Loss function and backpropagation\n",
    "\n",
    "To figure out how well our prediction was during each epoch, we'll use a basic loss function, mean squared error (MSE):\n",
    "\n",
    "$L(y,\\hat{y}) = ||~ y-\\hat{y} ~||^2$,\n",
    "\n",
    "ultimately trying to find $L_{\\rm min}$, defined by the point in parameter space where $\\nabla_{w_i} L = 0$.\n",
    "\n",
    "Per-iteration update: \n",
    "\n",
    "$ w_i \\to w_i - \\eta \\nabla_{w_i} L $,\n",
    "\n",
    "where $\\eta$ is known as the learning rate; too small and takes very long to converge, too big and you oscillate about the minimum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A basic example\n",
    "​\n",
    "We'll build an overly complex adding machine that will illustrate how neural nets work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(2, 1, bias=False))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = []\n",
    "num_samples = 10000\n",
    "\n",
    "for num in range(num_samples):\n",
    "    # Progress bar indicator\n",
    "    if num % (num_samples//5) == 0:\n",
    "        print('{0}: %: {1:.3f}'.format(num,num/num_samples * 100))\n",
    "        \n",
    "    # data prep\n",
    "    x = 4*torch.rand(2) #generate two random numbers uniformly on (0,4)\n",
    "    data, target = Variable(x), Variable(x[0] + x[1])\n",
    "    \n",
    "    # Feed forward through NN\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    total_loss.append(loss)\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(11,8))\n",
    "ax.plot(total_loss,marker='.',ls='',markersize=1.)\n",
    "ax.set_ylim(0,);ax.set_xlim(0,);ax.grid(alpha=0.2);\n",
    "ax.set_xlabel('training examples');ax.set_ylabel('mean squared loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=np.linspace(-5,8,100),[]\n",
    "\n",
    "for xx in x:\n",
    "    yy=model(torch.tensor([xx,2])).data.cpu().numpy()[0]\n",
    "    y.append(yy)\n",
    "y=np.array(y)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(11,8))\n",
    "ax.plot([-5,8],[-3,10],lw=2.0,label='actual',alpha=0.7)\n",
    "ax.fill_betweenx([-3,10],0,4,alpha=0.2)\n",
    "ax.scatter(x,y,marker='.',s=3.,label='prediction',color='r')\n",
    "ax.text(0.2,0,'Where we have \\ntraining data')\n",
    "ax.legend()\n",
    "ax.set_ylim(-3,10);ax.set_xlim(-5,8);\n",
    "ax.grid(alpha=0.2);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Neural Network\n",
    "\n",
    "![General Feed Forward Network](https://www.jeremyjordan.me/content/images/2017/07/Screen-Shot-2017-07-26-at-1.44.58-PM.png)\n",
    "\n",
    "For our case of learning linear relationships, the modification to the linear regression architecture is depicted below:\n",
    "\n",
    "\n",
    "![non-linear activation](data/img/linear_regression_activation.png)\n",
    "\n",
    "where\n",
    "\n",
    "$$\\varphi(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "is the so-called sigmoid function; this is typically the activation function that is first introduced, I think because of historical reasons. In modern practice, it finds most of its use in transforming single outputs from a NN into a probability. It's worth noting that if your NN will output multiple probabilities, for example, if your NN will categorize between black cats, red cats, white cats, etc., a multi-dimensional generalization of the sigmoid, called the softmax function, is typically used. \n",
    "\n",
    "The motivation behind adding an activation function is the hope that the NN model may capture non-linear relationships that exist in the data. Below are some commonly used activation functions. \n",
    "\n",
    "![activation functions](https://cdn-images-1.medium.com/max/1200/1*ZafDv3VUm60Eh10OeJu1vw.png)\n",
    "\n",
    "In practice, a lot of architectures use the rectified linear unit (ReLU), along with it's close cousin, the so-called leaky-ReLU. In introducing this idea though, we'll focus on the sigmoid which maps real numbers from $(-\\infty,\\infty) \\to [0,1]$.\n",
    "\n",
    "Of course our data is linear in the case of a straight line (!) but let's see what happens if we try to force a non-linear activation layer to capture a linear relationship.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear model for a linear relationship\n",
    "\n",
    "### Deep Feedforward Network with sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(2, 20),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(20, 1))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = []\n",
    "num_samples = 10000\n",
    "\n",
    "for num in range(num_samples):\n",
    "    # Progress bar indicator\n",
    "    if num % (num_samples//5) == 0:\n",
    "        print('{0}: %: {1:.3f}'.format(num,num/num_samples * 100))\n",
    "        \n",
    "    # data prep\n",
    "    x = 4*torch.rand(2) #generate two random numbers uniformly on (0,4)\n",
    "    data, target = Variable(x), Variable(x[0] + x[1])\n",
    "    \n",
    "    # Feed forward through NN\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    total_loss.append(loss)\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(11,8))\n",
    "ax.plot(total_loss,marker='.',ls='',markersize=.8)\n",
    "ax.set_ylim(0,);ax.set_xlim(0,);ax.grid(alpha=0.2);\n",
    "ax.set_xlabel('training examples');ax.set_ylabel('mean squared loss');\n",
    "\n",
    "x,y=np.linspace(-5,8,100),[]\n",
    "\n",
    "for xx in x:\n",
    "    yy=model(torch.tensor([xx,2])).data.cpu().numpy()[0]\n",
    "    y.append(yy)\n",
    "y=np.array(y)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(11,8))\n",
    "ax.plot([-5,8],[-3,10],lw=2.0,label='actual',alpha=0.7)\n",
    "ax.fill_betweenx([-3,10],0,4,alpha=0.2)\n",
    "ax.scatter(x,y,marker='.',s=3.,label='prediction',color='r')\n",
    "ax.text(0.2,0,'Where we have \\ntraining data')\n",
    "ax.legend()\n",
    "ax.set_ylim(-3,10);ax.set_xlim(-5,8);\n",
    "ax.grid(alpha=0.2);\n",
    "ax.set_title('Sigmoid activation function');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(2, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = []\n",
    "num_samples = 10000\n",
    "\n",
    "for num in range(num_samples):\n",
    "    # Progress bar indicator\n",
    "    if num % (num_samples//5) == 0:\n",
    "        print('{0}: %: {1:.3f}'.format(num,num/num_samples * 100))\n",
    "        \n",
    "    # data prep\n",
    "    x = 4*torch.rand(2) #generate two random numbers uniformly on (0,4)\n",
    "    data, target = Variable(x), Variable(x[0] + x[1])\n",
    "    \n",
    "    # Feed forward through NN\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    total_loss.append(loss)\n",
    "    \n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(11,8))\n",
    "ax.plot(total_loss,marker='.',ls='',markersize=.8)\n",
    "ax.set_ylim(0,);ax.set_xlim(0,);ax.grid(alpha=0.2);\n",
    "ax.set_xlabel('training examples');ax.set_ylabel('mean squared loss');\n",
    "\n",
    "x,y=np.linspace(-5,8,100),[]\n",
    "\n",
    "for xx in x:\n",
    "    yy=model(torch.tensor([xx,2])).data.cpu().numpy()[0]\n",
    "    y.append(yy)\n",
    "y=np.array(y)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(11,8))\n",
    "ax.plot([-5,8],[-3,10],lw=2.0,label='actual',alpha=0.7)\n",
    "ax.fill_betweenx([-3,10],0,4,alpha=0.2)\n",
    "ax.scatter(x,y,marker='.',s=3.,label='prediction',color='r')\n",
    "ax.text(0.2,0,'Where we have \\ntraining data')\n",
    "ax.legend()\n",
    "ax.set_ylim(-3,10);ax.set_xlim(-5,8);\n",
    "ax.grid(alpha=0.2);\n",
    "ax.set_title('ReLu activation function');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teaching a machine to draw circles\n",
    "\n",
    "Here the NN learns attempts to learn the 2d rotation matrix, parameterized by the generator of rotations in two dimensions:\n",
    "\n",
    "$R={\\begin{bmatrix}\\cos \\theta &-\\sin \\theta \\\\\\sin \\theta &\\cos \\theta \\\\\\end{bmatrix}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T05:42:28.228388Z",
     "start_time": "2019-04-30T05:42:28.187133Z"
    }
   },
   "outputs": [],
   "source": [
    "# First some helper functions for plotting and model training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def train_models(models, optimizers, num_samples=1000, circle_interval=1.0, save_models=False, cuda=torch.cuda.is_available(), recurrent=False):\n",
    "    total_loss = []\n",
    "    for num in range(num_samples):\n",
    "        # progress indicator \n",
    "        if num % (num_samples//20) ==0:\n",
    "            print('{0}: %: {1:.3f}'.format(num, num/num_samples * 100))\n",
    "            \n",
    "        # data calc \n",
    "        # take a random point on the circle of radius 1\n",
    "        x, theta = torch.ones(2), circle_interval*2*np.pi*torch.rand(1)\n",
    "        R = torch.zeros(2,2)\n",
    "        R[0,:] = torch.Tensor([np.cos(theta[0]),-np.sin(theta[0])])\n",
    "        R[1,:] = torch.Tensor([np.sin(theta[0]), np.cos(theta[0])])\n",
    "        \n",
    "        data, target = Variable(theta), Variable(torch.mv(R,x))\n",
    "        \n",
    "        # Check if GPU can be used\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "        # learning phases \n",
    "        for idx, model in enumerate(models):\n",
    "            loss_iter = []\n",
    "            # forward \n",
    "            if recurrent:\n",
    "                output = model(data,None)\n",
    "            else:\n",
    "                output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss_iter.append(loss.data.item())\n",
    "            # backward \n",
    "            optimizers[idx].zero_grad()\n",
    "            loss.backward()\n",
    "            optimizers[idx].step()\n",
    "        total_loss.append(np.mean(loss_iter))\n",
    "        \n",
    "    # save model state \n",
    "    if save_models:\n",
    "        for l,model in enumerate(models):\n",
    "            torch.save(model.state_dict(), 'rotations_{}.pth'.format(l))\n",
    "    return total_loss,theta\n",
    "        \n",
    "def plot_circles(models, offset=0, CI=False):\n",
    "    fig, axes = plt.subplots(figsize=(5*3,3.9),ncols=3)\n",
    "    x = torch.ones(2)\n",
    "    for k,ax in enumerate(axes):\n",
    "        ax.scatter(x[0],x[1], facecolors='none', edgecolors='r')\n",
    "        ax.scatter(x[0],x[1], facecolors='none', edgecolors='b')\n",
    "        x_real, y_real = [],[]\n",
    "        x_mean, y_mean = [],[]\n",
    "        x_std, y_std = [],[]\n",
    "        for theta in np.linspace((k+offset) *2*np.pi,(k+1+offset) *2*np.pi,300):\n",
    "            x_model,y_model = [],[]\n",
    "            # sythetic (real) data \n",
    "            data = Variable(torch.Tensor([theta]))#.cuda()\n",
    "            R = torch.zeros(2,2)\n",
    "            R[0,:] = torch.Tensor([np.cos(theta),-np.sin(theta)])\n",
    "            R[1,:] = torch.Tensor([np.sin(theta), np.cos(theta)])\n",
    "            real = torch.mv(R,x)\n",
    "            x_real.append(real[0].numpy())\n",
    "            y_real.append(real[1].numpy())\n",
    "            # predict w/ all models \n",
    "            for model in models:\n",
    "                if torch.cuda.is_available():\n",
    "                    model.cpu()\n",
    "                    outputs=model(data).data\n",
    "                    xx_model, yy_model = outputs[0],outputs[1]\n",
    "                    x_model.append(xx_model.numpy())\n",
    "                    y_model.append(yy_model.numpy())\n",
    "                else:\n",
    "                    outputs=model(data).data\n",
    "                    xx_model, yy_model = outputs[0],outputs[1]\n",
    "                    x_model.append(xx_model.numpy())\n",
    "                    y_model.append(yy_model.numpy())\n",
    "            # summarize all model predictions \n",
    "            x_mean.append(np.mean(x_model))\n",
    "            y_mean.append(np.mean(y_model))\n",
    "            x_std.append(np.std(x_model))\n",
    "            y_std.append(np.std(y_model))\n",
    "        # plotting data \n",
    "        ax.scatter(x_real,y_real, facecolors='none', edgecolors='r',label='real data',s=2.)\n",
    "        ax.scatter(x_mean,y_mean, facecolors='none', edgecolors='k',label='model data', alpha=0.9,s=2.)\n",
    "        if CI:\n",
    "            ax.fill_betweenx(y_mean,x_mean-3*np.array(x_std),x_mean+3*np.array(x_std), alpha=0.1,color='b')\n",
    "            ax.fill_between(x_mean,y_mean-3*np.array(y_std),y_mean+3*np.array(y_std), alpha=0.1,color='b')\n",
    "        ax.legend()\n",
    "        ax.set_ylim(-2,2);ax.set_xlim(-2,2);ax.grid(alpha=0.3)\n",
    "        ax.set_title(r'${}\\pi \\leq \\theta \\leq {}\\pi$'.format(2*(k+offset),2*(k+1+offset)),y=1.01);\n",
    "    \n",
    "    return x_mean, y_mean, np.array(x_std), np.array(y_std)\n",
    "        \n",
    "def weight_init(m): # so-called xavier normalization https://arxiv.org/abs/1211.5063\n",
    "    if isinstance(m, nn.Linear):\n",
    "        size = m.weight.size()\n",
    "        fan_out = size[0]\n",
    "        fan_in = size[1]\n",
    "        variance = np.sqrt(2.0/(fan_in + fan_out))\n",
    "        m.weight.data.normal_(0.0, variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T05:47:50.984630Z",
     "start_time": "2019-04-30T05:45:17.951543Z"
    }
   },
   "outputs": [],
   "source": [
    "num_nodes=10\n",
    "class Rotations(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Rotations, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(1,num_nodes),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(num_nodes,2))      \n",
    "    def forward(self, x):\n",
    "        out=self.layer1(x)\n",
    "        return out\n",
    "\n",
    "model = Rotations().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.MSELoss()\n",
    "print(model)\n",
    "\n",
    "total_loss, theta = train_models([model], [optimizer], num_samples=200000, circle_interval=2.0)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(11,8))\n",
    "ax.plot(total_loss,marker='.',ls='',markersize=.8)\n",
    "ax.set_ylim(0,);ax.set_xlim(0,);ax.grid(alpha=0.2);\n",
    "ax.set_xlabel('training examples');ax.set_ylabel('mean squared loss');\n",
    "\n",
    "output=plot_circles([model],offset=0,CI=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will a deeper network perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T06:05:29.936212Z",
     "start_time": "2019-04-30T06:00:59.778558Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add more layers to the model and see if performance on the test set increases\n",
    "%timeit\n",
    "num_nodes=10\n",
    "class Rotations(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Rotations, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(1,num_nodes),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(num_nodes,num_nodes),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(num_nodes,num_nodes),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(num_nodes,2))      \n",
    "    def forward(self, x):\n",
    "        out=self.layer1(x)\n",
    "        return out\n",
    "\n",
    "model=Rotations().to(device)\n",
    "optimizer=torch.optim.Adam(model.parameters())\n",
    "criterion=nn.MSELoss()\n",
    "print(model)\n",
    "\n",
    "total_loss,theta=train_models([model],[optimizer],num_samples=150000,circle_interval=2.0)\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(7,5))\n",
    "ax.plot(total_loss,marker='.',ls='',markersize=.8)\n",
    "ax.set_ylim(0,);ax.set_xlim(0,);ax.grid(alpha=0.2);\n",
    "ax.set_xlabel('training examples');ax.set_ylabel('mean squared loss');\n",
    "\n",
    "output=plot_circles([model],offset=0,CI=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple approach to apply the bayesian method described by Yarin Gal, is to take multiple of the same models and train them independently. This allows each model to take independent paths through parameter space, usually finding their way near some optimal minima. In practice, this allows you to hedge the risk of getting stuck in some local minima and missing out on the global one, if it exists. \n",
    "\n",
    "A visual way of understanding the situation of training a machine learning model, in general, is by considering a 3D surface plot where the x and y dimensions are two parameters you may modify, with the loss on the z axis, or height, which your aim is to minimize. \n",
    "\n",
    "![landscape of deep learning models](data/img/graphical-idea-backprop.png)\n",
    "\n",
    "The surface that the data carves out in this space is predicated by the data; the aim of the model design is then to build a model flexible and robust enough to find the global minima, but not overly complex enough to overfit and get stuck at a local minima. Also, if your model is too simple, it can skip right over all the minima altogether, and not learn the nuance of the process described by the data. Having too high/low of a learning rate can also make the training process difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognition and Transfer Learning\n",
    "\n",
    "![Convolutional Architecture](https://cdn-images-1.medium.com/max/1600/1*NQQiyYqJJj4PSYAeWvxutg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T06:06:43.622057Z",
     "start_time": "2019-04-30T06:06:41.147690Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T06:07:07.023913Z",
     "start_time": "2019-04-30T06:07:07.018256Z"
    }
   },
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T06:07:10.209986Z",
     "start_time": "2019-04-30T06:07:07.974608Z"
    }
   },
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T06:07:12.237746Z",
     "start_time": "2019-04-30T06:07:12.223104Z"
    }
   },
   "outputs": [],
   "source": [
    "# what are the labels?\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T06:07:15.082789Z",
     "start_time": "2019-04-30T06:07:15.065502Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build our first image recognition NN\n",
    "import torch.nn.functional as F\n",
    "class NotQuiteImageNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NotQuiteImageNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5) # same as reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T06:07:17.832929Z",
     "start_time": "2019-04-30T06:07:17.823074Z"
    }
   },
   "outputs": [],
   "source": [
    "imagenet = NotQuiteImageNet()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(imagenet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-30T06:11:24.017028Z",
     "start_time": "2019-04-30T06:07:20.705128Z"
    }
   },
   "outputs": [],
   "source": [
    "# running for short epochs to minimize compute time\n",
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = imagenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GroundTruth:', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = imagenet(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = imagenet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "Transfer learning is one of the most surprising and useful discoveries to come out of the computer vision community. Stated simply, transfer learning allows one model that was trained on different types of images, e.g. dogs vs cats, to be used for a different set of images, e.g. planes vs trains, while reducing the training time dramatically. When Google released ImageNet, they stated it took them over 24 hours to train the model on some of the most powerful GPUs available at the time. Now, with transfer learning, we will train a model in less than 5 minutes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The philosophy behind transfer learning is simple. We keep the \"base\" layers of a model frozen since the weights have already been tuned to identify patterns such as lines, circles, and other shapes, and insert layers at the end that will be tuned for the specific task at hand.\n",
    "\n",
    "![](data/img/NN_vision.png)\n",
    "\n",
    "![](data/img/transfer_learning.png)\n",
    "\n",
    "\n",
    "For our task, let's take a look at the King and Queen of the Miami food scene: \n",
    "\n",
    "**The Cuban Sandwich**  \n",
    "\n",
    "![](data/img/cubano.jpg)\n",
    "\n",
    "**The Stuffed Arepa**\n",
    "\n",
    "![](data/img/arepa.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T13:46:28.719471Z",
     "start_time": "2019-04-29T13:46:28.704878Z"
    }
   },
   "outputs": [],
   "source": [
    "#normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                 std=[0.229, 0.224, 0.225])\n",
    " \n",
    "data_transforms = {\n",
    "    'train':\n",
    "        transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor()]),\n",
    "    'validation':\n",
    "        transforms.Compose([\n",
    "            transforms.Resize((224,224)),\n",
    "            transforms.ToTensor()])}\n",
    " \n",
    "image_datasets = {\n",
    "    'train':\n",
    "        datasets.ImageFolder('data/cva_data/train', data_transforms['train']),\n",
    "    'validation':\n",
    "        datasets.ImageFolder('data/cva_data/validation', data_transforms['validation'])}\n",
    " \n",
    "dataloaders = {\n",
    "    'train':\n",
    "        torch.utils.data.DataLoader(\n",
    "            image_datasets['train'],\n",
    "            batch_size=32,\n",
    "            shuffle=True,\n",
    "            num_workers=4),\n",
    "    'validation':\n",
    "        torch.utils.data.DataLoader(\n",
    "            image_datasets['validation'],\n",
    "            batch_size=32,\n",
    "            shuffle=False,\n",
    "            num_workers=4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T13:47:07.106511Z",
     "start_time": "2019-04-29T13:47:05.715654Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    " \n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    " \n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2)).to(device)\n",
    " \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    " \n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    " \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    " \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    " \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    " \n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    " \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    " \n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    " \n",
    "            print(f'{phase} loss: {epoch_loss}, acc: {epoch_acc}')\n",
    "    return model\n",
    " \n",
    "model_trained = train_model(model, criterion, optimizer, num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_trained.state_dict(),'models/cva_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T13:47:11.945605Z",
     "start_time": "2019-04-29T13:47:11.110004Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=False).to(device)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2)).to(device)\n",
    "model.load_state_dict(torch.load('models/cva_weights.h5'))\n",
    "model.eval() # stop training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T13:47:15.486794Z",
     "start_time": "2019-04-29T13:47:15.441762Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_img_paths = [\"data/cva_data/validation/arepas/00000165.jpg\",\n",
    "                        \"data/cva_data/validation/cubanos/00000037.jpg\",\n",
    "                        \"data/cva_data/validation/cubanos/00000061.jpg\",\n",
    "                        \"data/cva_data/validation/arepas/00000003.jpeg\"]\n",
    "img_list = [Image.open(img_path) for img_path in validation_img_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T13:54:38.976494Z",
     "start_time": "2019-04-29T13:54:37.385606Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_batch = torch.stack([data_transforms['validation'](img).to(device)\n",
    "                                for img in img_list])\n",
    " \n",
    "pred_logits_tensor = model(validation_batch)\n",
    "pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T13:54:40.651430Z",
     "start_time": "2019-04-29T13:54:40.088288Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(img_list), figsize=(20, 5))\n",
    "for i, img in enumerate(img_list):\n",
    "    ax = axs[i]\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"{:.0f}% Arepa, {:.0f}% Cubano\".format(100*pred_probs[i,0],\n",
    "                                                          100*pred_probs[i,1]))\n",
    "    ax.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `Datasets` and `Dataloaders`\n",
    "\n",
    "In PyTorch, you'll usually create or import a `Dataset` subclass to represent your data. Once you've done that, you can use it to instantiate a `Dataloader` object which allows you to easily iterate over your training set in `BATCH_SIZE` chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "num_classes = 10\n",
    "num_channels = 1\n",
    "batch_size = 64\n",
    "id_to_label = {\n",
    "    0 :'T-shirt/top',\n",
    "    1 :'Trouser',\n",
    "    2 :'Pullover',\n",
    "    3 :'Dress',\n",
    "    4 :'Coat',\n",
    "    5 :'Sandal',\n",
    "    6 :'Shirt',\n",
    "    7 :'Sneaker',\n",
    "    8 :'Bag',\n",
    "    9 :'Ankle boot'}\n",
    "\n",
    "\n",
    "class FashionDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, \n",
    "                 image_size, num_channels, image_transform=None):\n",
    "        self.num_channels = num_channels\n",
    "        self.image_size = image_size\n",
    "        self.image_transform = image_transform\n",
    "        data_df = pd.read_csv(path)\n",
    "        self.X = data_df.values[:, 1:]\n",
    "        self.X = self.X.reshape(-1, image_size, image_size, num_channels)\n",
    "        self.X = self.X.astype('float32')\n",
    "        self.y = data_df.values[:, 0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        batch_X, batch_y = self.X[index], self.y[index]\n",
    "        if self.image_transform is not None:\n",
    "            batch_X = self.image_transform(batch_X)\n",
    "        return batch_X, batch_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "# This simple transform coverts the image from an numpy array\n",
    "# to a PyTorch tensor and remaps its values from 0-255 to 0-1. \n",
    "# Many other types of transformations are available, and they \n",
    "# can easily be composed into a pipeline. For more info see: \n",
    "# https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "image_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = FashionDataset(\n",
    "    'fashionmnist/fashion-mnist_train.csv', \n",
    "    image_size, \n",
    "    num_channels, \n",
    "    image_transform)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "val_dataset = FashionDataset(\n",
    "    'fashionmnist/fashion-mnist_test.csv', \n",
    "    image_size, \n",
    "    num_channels, \n",
    "    image_transform)\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some examples from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(data, labels, image_size):\n",
    "    size = 28\n",
    "    fig, axes = plt.subplots(\n",
    "        1, data.shape[0], figsize=(16, 4), \n",
    "        subplot_kw={'xticks':[], 'yticks':[]},\n",
    "        gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(data[i].reshape(image_size, image_size), cmap='binary')\n",
    "        ax.set_xlabel(labels[i])\n",
    "        \n",
    "images = train_dataset.X[:10]\n",
    "class_ids = train_dataset.y[:10]\n",
    "class_labels = [id_to_label[class_id] for class_id in class_ids]\n",
    "plot_images(images, class_labels, image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline network uses a single convolution with only 4 filters. Because of the simplicity of our dataset, it still manages to achieve nearly 90% accuracy after only 5 epochs.\n",
    "\n",
    "Experiment and see if you can increase the accuracy on the validation set to above 95%.\n",
    "\n",
    "Things you might try:\n",
    "\n",
    "* Increasing the number of filters per convolution.\n",
    "* Adding more convolutions.\n",
    "* Adding a `BatchNorm2d` layer after `Conv2d`.\n",
    "* Increasing the number of epochs.\n",
    "* Changing the kernel size.\n",
    "* Using different types of pooling or using stride > 1 in convolutional layers instead of pooling.\n",
    "\n",
    "You might also find the [PyTorch API reference](https://pytorch.org/docs/stable/nn.html) useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # Add more conv2d layers\n",
    "        # recall that the input size for the new layer is 16! Make the output 32 and 64 \n",
    "        # to create 3 total convolution layers\n",
    "        self.linear = nn.Linear(14 * 14 * 16, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ## Don't forgot to add the forward method!\n",
    "        # Hint: After passing through your convolutional layers, reshape your vector \n",
    "        # before passing to the linear layer\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate the model.    \n",
    "model = FashionModel(num_channels, num_classes)\n",
    "\n",
    "# Send the model's tensors to the GPU if available.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "log_freq = 100\n",
    "checkpoint_path = 'checkpoint.pickle'\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()  # Switch to training mode.\n",
    "    print(f'Starting epoch {epoch}.')\n",
    "    epoch_start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    for batch_id, (batch_X, batch_y) in enumerate(train_dataloader):\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        output = model(batch_X)\n",
    "        loss = criterion(output, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Periodically print the loss and prediction accuracy.\n",
    "        running_loss += loss.item()\n",
    "        y_pred = output.argmax(dim=-1)\n",
    "        running_accuracy += accuracy_score(batch_y.cpu(), y_pred.cpu())\n",
    "        if batch_id % log_freq == log_freq - 1:\n",
    "            average_loss = running_loss / log_freq\n",
    "            average_accuracy = running_accuracy / log_freq\n",
    "            print(f'Mini-batch: {batch_id + 1}/{len(train_dataloader)} '\n",
    "                  f'Loss: {average_loss:.5f} Accuracy: {average_accuracy:.5f}')\n",
    "            running_loss = 0.0\n",
    "            running_accuracy = 0.0\n",
    "            \n",
    "    # Log elapsed_time for the epoch.            \n",
    "    elapsed_time = time.time() - epoch_start_time\n",
    "    print(f'\\nEpoch {epoch} completed in {elapsed_time // 60:.0f} minutes '\n",
    "          f'{elapsed_time % 60:.0f} seconds.')\n",
    "    \n",
    "    # Calculate and log loss on validation set.\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        for batch_id, (batch_X, batch_y) in enumerate(val_dataloader):\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            output = model(batch_X)\n",
    "            loss = criterion(output, batch_y)\n",
    "            running_loss += loss.item()\n",
    "            y_pred = output.argmax(dim=-1)  \n",
    "            running_accuracy += accuracy_score(batch_y, y_pred)\n",
    "        average_loss = running_loss / len(val_dataloader)\n",
    "        average_accuracy = running_accuracy / len(val_dataloader)\n",
    "        print(f'Val Loss: {average_loss:.5f} Val Accuracy: {average_accuracy:.5f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Character Level Generation\n",
    "\n",
    "Text generation is a fun way to familiarize yourself with Recurrent Neural Nets.\n",
    "\n",
    "In this notebook, we will deal with **character-level** text generation and why they can be just as useful as word-level text generation.\n",
    "\n",
    "For this example, we'll be using text files to generate code similar to our input. In other words, if we put in Trump tweets, our generator should output words that sound like Trump.\n",
    "\n",
    "### Our current understanding of RNNs\n",
    "![](data/img/LSTM_next_character.png)\n",
    "\n",
    "\n",
    "### Reminder\n",
    "\n",
    "![](data/img/rnn_unrolling.png)\n",
    "\n",
    "#### \"RNNs have a hidden state that feeds back into the cell at the next time step\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is actually going on?\n",
    "\n",
    "### Example with sequence length 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/img/rnn_forward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about the backwards pass?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/img/rnn_backward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install unidecode\n",
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in text and change unicode characters to ASCII\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in file to train RNN\n",
    "file = unidecode.unidecode(open('data/shakespeare.txt').read())\n",
    "file_len = len(file)\n",
    "print(f'file_len = {file_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give our model inputs from this large string of text, we'll split it up into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len = 400\n",
    "\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "\n",
    "This model will take as input the character for step $t$ and is expected to output the next character for step $t+1$. There are three layers - one linear layer that encodes the input character into an internal state, one GRU layer (which may itself have multiple layers) that operates on that internal state and a hidden state, and a decoder layer that outputs the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(output.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.randn(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs and Targets\n",
    "\n",
    "Now that we've defined our model, we need to give it both input data, via our chunks, and our target data. Each character is one-hot encoded to the vocab size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char2tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for char in range(len(string)):\n",
    "        if string[char] in all_characters:\n",
    "            tensor[char] = all_characters.index(string[char])\n",
    "        else:\n",
    "            tensor[char] = 94 #predict space if character unknown\n",
    "        \n",
    "    return Variable(tensor)\n",
    "\n",
    "# Let's see it in action.\n",
    "print(char2tensor('Metis0123abczABC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can generate chunks of data, we can build our inputs and targets.\n",
    "\n",
    "Our inputs will be all of the chunk except for the last letter. \n",
    "\n",
    "Our target will be all of the chunk except for the first letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    chunk = random_chunk()\n",
    "    inp = char2tensor(chunk[:-1])\n",
    "    target = char2tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, prime_str='A', predict_len=100, temperature=0.8):\n",
    "    \n",
    "    hidden = model.init_hidden()\n",
    "    prime_input = char2tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "    \n",
    "    # use priming string to build up hidden state\n",
    "    \n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = model(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = model(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char2tensor(predicted_char)\n",
    "        \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s/60)\n",
    "    s -= m*60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual training part\n",
    "def train(inp, target):\n",
    "    hidden = model.init_hidden()\n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for char in range(chunk_len):\n",
    "        output, hidden = model(inp[char], hidden)\n",
    "        loss += criterion(output, target[char].unsqueeze(0))\n",
    "\n",
    "    loss.backward()\n",
    "    model_optimizer.step()\n",
    "\n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_epochs = 1000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 256\n",
    "n_layers = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "# model declaration\n",
    "model = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
    "model_optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate(model, 'A ', 100), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump = torch.load('models/potus.pt')\n",
    "billy = torch.load('models/shakespeare.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Trump\n",
    "print(evaluate(trump, 'Mueller Witch Hunt! ', predict_len=140, temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Billy Shakespeare\n",
    "print(evaluate(billy, 'To be or not to be: ', predict_len=200, temperature=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "[tensor images](https://hackernoon.com/learning-ai-if-you-suck-at-math-p4-tensors-illustrated-with-cats-27f0002c9b32)\n",
    "\n",
    "[alien vs predator](https://deepsense.ai/keras-vs-pytorch-avp-transfer-learning/)\n",
    "\n",
    "[unreasonable reffectiveness of neural nets](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "\n",
    "[pytorch.org](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "\n",
    "[Richard Galvez](https://richardagalvez.github.io/)\n",
    "\n",
    "[Visualizing and Understanding Convolutional Networks](https://arxiv.org/pdf/1311.2901.pdf)\n",
    "\n",
    "[Transfer Learning Image](https://www.researchgate.net/figure/Illustration-of-transfer-learning-concept-where-the-rst-layers-in-network-A-and-network-B_fig2_316748306)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
